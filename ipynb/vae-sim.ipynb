{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (trainer.py, line 47)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/home/juermieboop/miniconda3/envs/catvae/lib/python3.8/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3343\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-28658379d93f>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0;36m, in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n\u001b[0;31m    from catvae.trainer import LightningVAE\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"/home/juermieboop/Documents/research/catvae/catvae/trainer.py\"\u001b[0;36m, line \u001b[0;32m47\u001b[0m\n\u001b[0;31m    deep_decoder=self.hparams.deep_decoder,\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import unittest\n",
    "from catvae.trainer import LightningVAE\n",
    "from catvae.sim import multinomial_bioms\n",
    "from biom import Table\n",
    "from biom.util import biom_open\n",
    "import numpy as np\n",
    "from pytorch_lightning import Trainer\n",
    "import argparse\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "sims = multinomial_bioms(k=4, D=10, N=500, M=100)\n",
    "Y = sims['Y']\n",
    "parts = Y.shape[0] // 10\n",
    "samp_ids = list(map(str, range(Y.shape[0])))\n",
    "obs_ids = list(map(str, range(Y.shape[1])))\n",
    "train = Table(Y[:parts * 8].T, obs_ids, samp_ids[:parts * 8])\n",
    "test = Table(Y[parts * 8 : parts * 9].T,\n",
    "             obs_ids, samp_ids[parts * 8 : parts * 9])\n",
    "valid = Table(Y[parts * 9:].T, obs_ids, samp_ids[parts * 9:])\n",
    "tree = sims\n",
    "with biom_open('train.biom', 'w') as f:\n",
    "    train.to_hdf5(f, 'train')\n",
    "with biom_open('test.biom', 'w') as f:\n",
    "    test.to_hdf5(f, 'test')\n",
    "with biom_open('valid.biom', 'w') as f:\n",
    "    valid.to_hdf5(f, 'valid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "output_dir = 'output'\n",
    "args = [\n",
    "    '--train-biom', 'train.biom',\n",
    "    '--test-biom', 'test.biom',\n",
    "    '--val-biom', 'valid.biom',\n",
    "    '--output-directory', output_dir,\n",
    "    '--epochs', '1024',\n",
    "    '--batch-size', '50',\n",
    "    '--num-workers', '10',\n",
    "    '--scheduler', 'cosine',\n",
    "    '--learning-rate', '1e-2',\n",
    "    '--n-latent', '4',\n",
    "    '--gpus', '1'\n",
    "]\n",
    "parser = argparse.ArgumentParser(add_help=False)\n",
    "parser = LightningCountVAE.add_model_specific_args(parser)\n",
    "parser.add_argument('--num-workers', type=int)\n",
    "parser.add_argument('--gpus', type=int)\n",
    "args = parser.parse_args(args)\n",
    "model = LightningCountVAE(args)\n",
    "model.set_eigs(sims['eigvectors'], sims['eigs'])\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=args.epochs,\n",
    "    gpus=args.gpus,\n",
    "    check_val_every_n_epoch=10,\n",
    "    # profiler=profiler,\n",
    "    fast_dev_run=False,\n",
    "    # auto_scale_batch_size='power'\n",
    ")\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.gt_eigvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir lightning_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access 'lightning_logs/version_0/checkpoints': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!ls lightning_logs/version_0/checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pytorch_lightning'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-1964fecbf68e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch_lightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcheckpoint_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'lightning_logs/version_0/checkpoints'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{checkpoint_dir}/epoch=399.ckpt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLightningCountVAE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pytorch_lightning'"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.callbacks.model_checkpoint import ModelCheckpoint\n",
    "checkpoint_dir = 'lightning_logs/version_0/checkpoints'\n",
    "path = f'{checkpoint_dir}/epoch=399.ckpt'\n",
    "model = LightningCountVAE.load_from_checkpoint(path).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from mavi.dataset.biom import BiomDataset\n",
    "from skbio.stats.composition import alr_inv, closure\n",
    "valid_dataset = BiomDataset(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = [] \n",
    "pred_z = []\n",
    "pred_probs = []\n",
    "counts = []\n",
    "for i in range(len(valid_dataset)):\n",
    "    cnts, batch_idx = valid_dataset[i]\n",
    "    counts.append(closure(cnts))\n",
    "    cnts = torch.Tensor(cnts).cuda().unsqueeze(0)\n",
    "    smoothed_cnts = cnts + 1\n",
    "    res = model.model.inference(smoothed_cnts)\n",
    "    z.append(sims['z'][parts * 8 + i])\n",
    "    pred_z.append(res['qz_m'].cpu().detach().numpy())\n",
    "    pred_probs.append(alr_inv(res['px_mean'].cpu().detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = np.vstack(counts)\n",
    "pred_probs = np.vstack(pred_probs)\n",
    "pred_z = np.vstack(pred_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist\n",
    "d_predz = pdist(pred_z)\n",
    "dz = pdist(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.vstack(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(pred_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(z)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from umap import UMAP\n",
    "\n",
    "reducer = UMAP()\n",
    "embed1 = reducer.fit_transform(pred_z)\n",
    "embed2 = reducer.fit_transform(z)\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].scatter(embed1[:, 0], embed1[:, 1])\n",
    "ax[1].scatter(embed2[:, 0], embed2[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(d_predz, dz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "pearsonr(d_predz, dz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = model.model.get_loadings()\n",
    "d_estW = pdist(W)\n",
    "dW = pdist(sims['W'])\n",
    "plt.scatter(dW, d_estW)\n",
    "print(pearsonr(dW, d_estW))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam = np.ravel(sims['z'][parts * 8 : parts * 8 + 50] @ sims['W'].T)\n",
    "pred_lam = np.ravel(z @ W.T)\n",
    "plt.scatter(lam, pred_lam)\n",
    "print(pearsonr(lam, pred_lam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.shape, W.shape, lam.shape, sims['z'].shape, sims['W'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import entropy\n",
    "ens = []\n",
    "for i in range(counts.shape[0]):\n",
    "    e = entropy(counts[i], pred_probs[i])\n",
    "    ens.append(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(ens, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(pred_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(counts.ravel()+1, pred_probs.ravel()+1)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearsonr(counts.ravel()+1, pred_probs.ravel()+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.exp(model.model.encoder.variational_logvars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import unittest\n",
    "from catvae.trainer import MultBatchVAE, BiomDataModule\n",
    "from catvae.sim import multinomial_batch_bioms\n",
    "from biom import Table\n",
    "from biom.util import biom_open\n",
    "import numpy as np\n",
    "from pytorch_lightning import Trainer\n",
    "import torch\n",
    "import argparse\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "from pytorch_lightning.profiler import AdvancedProfiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'basis.nwk'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "k = 20\n",
    "C = 3\n",
    "D = 100\n",
    "sims = multinomial_batch_bioms(k=k, D=D, N=2000, M=1e6, C=C)\n",
    "Y = sims['Y']\n",
    "parts = Y.shape[0] // 10\n",
    "samp_ids = list(map(str, range(Y.shape[0])))\n",
    "obs_ids = list(map(str, range(Y.shape[1])))\n",
    "train = Table(Y[:parts * 8].T, obs_ids, samp_ids[:parts * 8])\n",
    "test = Table(Y[parts * 8 : parts * 9].T,\n",
    "             obs_ids, samp_ids[parts * 8 : parts * 9])\n",
    "valid = Table(Y[parts * 9:].T, obs_ids, samp_ids[parts * 9:])\n",
    "tree = sims\n",
    "with biom_open('train.biom', 'w') as f:\n",
    "    train.to_hdf5(f, 'train')\n",
    "with biom_open('test.biom', 'w') as f:\n",
    "    test.to_hdf5(f, 'test')\n",
    "with biom_open('valid.biom', 'w') as f:\n",
    "    valid.to_hdf5(f, 'valid')\n",
    "\n",
    "md = pd.DataFrame({'batch_category': sims['batch_idx']}, index=samp_ids)\n",
    "md.index.name = 'sampleid'\n",
    "md.to_csv('metadata.txt', sep='\\t')\n",
    "batch_priors = pd.Series(sims['alphaILR'])\n",
    "batch_priors.to_csv('batch_priors.txt', sep='\\t')\n",
    "\n",
    "sims['tree'].write('basis.nwk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run batch effects removal VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultBatchVAE(\n",
      "  (vae): LinearBatchVAE(\n",
      "    (encoder): Encoder(\n",
      "      (encoder): Linear(in_features=99, out_features=20, bias=True)\n",
      "    )\n",
      "    (decoder): ParametrizedLinear(\n",
      "      in_features=20, out_features=99, bias=True\n",
      "      (parametrizations): ModuleDict(\n",
      "        (weight): GrassmannianTall(n=99, k=20, triv=expm)\n",
      "      )\n",
      "    )\n",
      "    (beta): Embedding(3, 99)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "output_dir = 'output'\n",
    "\n",
    "dm = BiomDataModule('train.biom', 'test.biom', 'valid.biom',\n",
    "                    metadata='metadata.txt',\n",
    "                    batch_category='batch_category',\n",
    "                    batch_size=50)\n",
    "model = MultBatchVAE(n_input=D, n_latent=k,\n",
    "                     n_hidden=16, n_batches=C,\n",
    "                     basis='basis.nwk', batch_prior='batch_priors.txt',\n",
    "                     dropout=0.5, bias=True, batch_norm=True,\n",
    "                     encoder_depth=1, learning_rate=0.1,\n",
    "                     scheduler='cosine', transform='pseudocount')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name | Type           | Params\n",
      "----------------------------------------\n",
      "0 | vae  | LinearBatchVAE | 4.5 K \n",
      "----------------------------------------\n",
      "4.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.5 K     Total params\n",
      "0.018     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jmorton/miniconda3/envs/catvae/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/Users/jmorton/miniconda3/envs/catvae/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3f7d05a930540499ec5deed21094d90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3242776ab2d44bcbb8c352b55a5976dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jmorton/miniconda3/envs/catvae/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    max_epochs=3,\n",
    "    gpus=0,\n",
    "    check_val_every_n_epoch=1,\n",
    "    # profiler=profiler,\n",
    "    fast_dev_run=False,\n",
    "    # auto_scale_batch_size='power'\n",
    ")\n",
    "trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#W = model.get_embedding(exclude_batch=True, eps=1e-3).detach().cpu().numpy()\n",
    "W = model.model.decoder.weight.detach().cpu().numpy()\n",
    "d_estW = pdist(W)\n",
    "simW = sims['W'] / np.sqrt(sims['eigs'])\n",
    "dW = pdist(simW)\n",
    "\n",
    "plt.scatter(dW, d_estW, s=1)\n",
    "plt.plot(np.linspace(0.3, 1), np.linspace(0.3, 1), 'r')\n",
    "plt.xlabel('Predicted correlations')\n",
    "plt.ylabel('Actual correlations')\n",
    "\n",
    "print(pearsonr(dW, d_estW))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.Tensor(sims['Y']).float()\n",
    "b = torch.Tensor(sims['batch_idx']).long()\n",
    "z = model.model.encode(x, b)\n",
    "\n",
    "dsimz = pdist(sims['z'])\n",
    "dz = pdist(z.detach().cpu().numpy())\n",
    "plt.scatter(dz, dsimz, s=1)\n",
    "plt.xlabel('Predicted distance z')\n",
    "plt.ylabel('Actual distance z')\n",
    "print(pearsonr(dz, dsimz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "batch_pred = model.discriminator(x)\n",
    "batch_ids = torch.Tensor(sims['batch_idx']).long()\n",
    "\n",
    "acc = accuracy_score(batch_pred.detach().cpu().numpy().argmax(axis=1),\n",
    "                     batch_ids.detach().cpu().numpy())            \n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.Tensor(sims['Y']).float()\n",
    "z = model.to_latent(x)\n",
    "\n",
    "dsimz = pdist(sims['z'])\n",
    "dz = pdist(z.detach().cpu().numpy())\n",
    "plt.scatter(dz, dsimz, s=1)\n",
    "plt.xlabel('Predicted distance z')\n",
    "plt.ylabel('Actual distance z')\n",
    "print(pearsonr(dz, dsimz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.argsort(md['batch_category'].values[:parts * 8])\n",
    "sns.heatmap(z[i].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = model.model.beta.weight.detach().cpu().numpy().T\n",
    "d_estB = pdist(B)\n",
    "simB = sims['B'].T\n",
    "dB = pdist(simB)\n",
    "\n",
    "plt.scatter(dB, d_estB, s=1)\n",
    "#plt.plot(np.linspace(0, 4), np.linspace(0, 4), 'r')\n",
    "plt.xlabel('Predicted batch correlations')\n",
    "plt.ylabel('Actual batch correlations')\n",
    "\n",
    "print(pearsonr(dB, d_estB))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
